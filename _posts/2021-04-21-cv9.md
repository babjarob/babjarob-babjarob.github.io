---
layout: post
title: Cvičenie 9
excerpt: "Hľadanie extrémov 2"
tags:
  - najväčší spád
  - konjugované smery
  - konjugované gradienty
  - simulované žíhaní

---


## Minimalizácia v smeroch

Ďalšia skupina metód na hľadanie extrémov sú také, ktoré premieňajú problém hľadania extrému vo viac dimenziách na postupné hľadanie extrému v jednom rozmere. Zvolí sa smer, v ktorom sa nájde minimum a v nájdenom minime sa volí nový smer, ktorý sa opäť minimalizuje. Takto to pokračuje, až kým sa nedostaneme k požadovanej presnosti. Minimalizácia v smeroch bázových vektorov nie je zrovna najefektívnejšia, viď príklady z prednášky. Volia sa preto sofistikovanejŠie metódy. Jednou z možností je vybrať sa smerom najprudŠieho spádu v danom mieste. To znamená, že minimalizujeme v smere záporného gradientu. Nevýhodou však je, že ak nájdeme minimum, gradient je v tom minime kolmý k predchádzajúcemu. Vzniká tým pádom ten istý problém ako v predchádzajúcom prípade. Optimálnou voľbou mnohokrát býva metóda konjugovaných gradientov. Stiahnite si [skript](http://babjarob.github.io/cv9/Multidimensional_optimisation_author.m) k takémuto typu optimalizácie. Vysvetlenie nájdete vo videu od začiatku do času 21:00. Detailnejšie vysvetlenie v [pdf](http://babjarob.github.io/cv9/conj_grad.pdf).

<div class="embed-responsive embed-responsive-16by9">
<iframe width="560" height="315" src="https://www.youtube.com/embed/UejgqnPNZzA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

## Simulované žíhaní

Kombinatorická minimalizácia je vhodná na diskrétne úlohy ktoré majú veľa stupňov voľnosti a je dôležitejšie nájsť približnú hodnotu globálneho minima než jeho presnú hodnotu, čo by bolo časovo zbytočne náročné. Často sa využíva pre úlohy, kde exaktné gradientné metódy zlyhávajú. Najtypickejší prípad využitia simulovaného žíhania je problém obchodného cestujúceho, popísaného v prednáške a vo videu.

<div class="embed-responsive embed-responsive-16by9">
<iframe width="560" height="315" src="https://www.youtube.com/embed/NhSHKzOeD1o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

K videu si stiahnite [skript](http://babjarob.github.io/cv9/annealing/) a prejdite si úvod k úlohe a implementačnú časť od začiatku videa do 36:05. 

## Pre záujemcov

  * Gradientné metódy za využívajú aj pri trénovaní neurónových sietí. Trénovanie neurónovej siete sa dá vlastne preformulovať ako problém hľadania minima. Algoritmus je zrozumiteľne popísaný vo [videu](https://www.youtube.com/watch?v=Ilg3gGewQ5U&t=63s&ab_channel=3Blue1Brown) od 3Blue1Brown a nazýva sa backpropagation. 